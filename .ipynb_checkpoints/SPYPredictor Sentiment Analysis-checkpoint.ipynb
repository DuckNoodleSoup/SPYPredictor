{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SPYPredictor: Sentiment Analysis</h2>\n",
    "Final Project Component Shuzo Katayama, 11 December 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a significant portion of this project, I would like to focus on running sentiment analysis on the news headlines of a particular day as data to train the SPYPredictor. Broadly, I plan to take several news headlines on a certain day, run the headline through a trained model to analyse each headline, average the scores for all the headlines in a day, and use that result as the news sentiment indicator for that day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is definitely a much more difficult task than I previously imagined because of the lack of very convenient data. Data that is rich in the number of dates is not pre-labelled with 'positive' or 'negative', making impossible to train a model with that dataset, and datasets with labels are often irrelevant (being comprised of tweets or otherwise, not newspaper headlines), or are very limited in terms of dates. In order to curtail this problem the best I can, I am going to attempt to first, train a model with newspaper headline training data, and then use that model to label a larger dataset with 'positive' or 'negative'. Ultimately, I will use this self-labelled larger dataset to train the SPYPredictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: \\\n",
    "Labelled Headlines : https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news \\\n",
    "Unlabelled Headlines: https://www.kaggle.com/therohk/million-headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works Cited:\n",
    "\n",
    "\"6.2. Feature extraction\", Scikit-Learn Documentation  \\\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "\"VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text\", by C.J. Hutto Eric Gilbert, Georgia Institute of Technology, 2014 http://eegilbert.org/papers/icwsm14.vader.hutto.pdf\n",
    "\n",
    "\"Python | Sentiment Analysis using VADER\", Geeksforgeeks.org, 2019 https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>negative</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>negative</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>negative</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>negative</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                           headline\n",
       "0      neutral  According to Gran , the company has no plans t...\n",
       "1      neutral  Technopolis plans to develop in stages an area...\n",
       "2     negative  The international electronic industry company ...\n",
       "3     positive  With the new production plant the company woul...\n",
       "4     positive  According to the company 's updated strategy f...\n",
       "...        ...                                                ...\n",
       "4841  negative  LONDON MarketWatch -- Share prices ended lower...\n",
       "4842   neutral  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4844  negative  Net sales of the Paper segment decreased to EU...\n",
       "4845  negative  Sales in Finland decreased by 10.5 % in Januar...\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_headlines = pd.read_csv('FinancialHeadlines.csv', encoding = \"ISO-8859-1\")\n",
    "l_headlines\n",
    "\n",
    "# Encoding change from StackOverflow: \"https://stackoverflow.com/questions/18171739/unicodedecodeerror-\n",
    "# when-reading-csv-file-in-pandas-with-python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = l_headlines.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiments to values: -1, negative; 0, neutral; 1, positive\n",
    "for item in a:\n",
    "    if item[0] == \"negative\":\n",
    "        item[0] = -1\n",
    "    elif item[0] == \"neutral\":\n",
    "        item[0] = 0\n",
    "    else:\n",
    "        item[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = a[:, 1]\n",
    "y = a[:, 0]\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\"6.2. Feature extraction\", Scikit-Learn Documentation\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature extraction from documentation: https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "vectorizer = CountVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X).toarray()\n",
    "X_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 0.000, test: 0.329\n",
      "R^2 train: 0.999, test: 0.154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train_pred = classifier.predict(X_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first trained the model on 100 trees. Here, the model performed very poorly. It learned from the training data well, but when it was put to the test, the R<sup>2</sup> dropped to 0.107, meaning that the model did not generalise at all. Even on 1000 trees, the test R<sup>2</sup> turned out to be 0.154 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is generally flawed and difficult to get a hold of, I will instead use VADER. Unlike other models for prediction, VADER does not learn by training from data directly. Instead, the VADER model was created by researchers as a model that already did the work of learning, and is able to generalise. The model takes a number of general rules that takes grammar and syntax into consideration, along with a preset list of lexical features, to predict sentiment in unseen text. In order to be able to use the headline sentiment data in the SPYPredictor, I will use the large dataset and use the collection of sentiment predictions as data for the SPYPredictor\n",
    "\n",
    "Reference: \n",
    "\n",
    "\"VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text\", by C.J. Hutto Eric Gilbert, Georgia Institute of Technology, 2014 http://eegilbert.org/papers/icwsm14.vader.hutto.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186013</th>\n",
       "      <td>20191231</td>\n",
       "      <td>vision of flames approaching corryong in victoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186014</th>\n",
       "      <td>20191231</td>\n",
       "      <td>wa police and government backflip on drug amne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186015</th>\n",
       "      <td>20191231</td>\n",
       "      <td>we have fears for their safety: victorian premier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186016</th>\n",
       "      <td>20191231</td>\n",
       "      <td>when do the 20s start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186017</th>\n",
       "      <td>20191231</td>\n",
       "      <td>yarraville shooting woman dead man critically ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1186018 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         publish_date                                      headline_text\n",
       "0            20030219  aba decides against community broadcasting lic...\n",
       "1            20030219     act fire witnesses must be aware of defamation\n",
       "2            20030219     a g calls for infrastructure protection summit\n",
       "3            20030219           air nz staff in aust strike for pay rise\n",
       "4            20030219      air nz strike to affect australian travellers\n",
       "...               ...                                                ...\n",
       "1186013      20191231  vision of flames approaching corryong in victoria\n",
       "1186014      20191231  wa police and government backflip on drug amne...\n",
       "1186015      20191231  we have fears for their safety: victorian premier\n",
       "1186016      20191231                              when do the 20s start\n",
       "1186017      20191231  yarraville shooting woman dead man critically ...\n",
       "\n",
       "[1186018 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = pd.read_csv('abcnews-date-text.csv', encoding = \"ISO-8859-1\")\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = headlines.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the array with average scores as having 6151 (days) rows, and 2 columns\n",
    "r = 6151\n",
    "c = 2\n",
    "total_scores = np.empty((r, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.00302190e+07, -1.07072864e-01],\n",
       "       [ 2.00302200e+07, -1.07921200e-01],\n",
       "       [ 2.00302210e+07, -9.93488000e-02],\n",
       "       ...,\n",
       "       [ 2.01912280e+07, -9.96333333e-03],\n",
       "       [ 2.01912290e+07, -9.81674419e-02],\n",
       "       [ 2.01912300e+07, -1.71289130e-01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop through large headlines dataset. Get a compound score for each headline\n",
    "# After each headline for a particular date is referenced, add it to the \n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "publish_date = a[0, 0]\n",
    "counter = 1\n",
    "score_sum = 0\n",
    "total_counter = 0\n",
    "\n",
    "for item in a:\n",
    "    if item[0] == publish_date:\n",
    "        scores = sid.polarity_scores(item[1])\n",
    "        compound_score = scores['compound']\n",
    "        score_sum = score_sum + compound_score\n",
    "        counter = counter+1\n",
    "    else:\n",
    "        total_scores[total_counter, 0] = publish_date\n",
    "        total_scores[total_counter, 1] = (score_sum/counter)\n",
    "        \n",
    "        publish_date = item[0]\n",
    "        counter = 1\n",
    "        total_counter = total_counter+1\n",
    "        score_sum = 0\n",
    "\n",
    "total_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \"Python | Sentiment Analysis using VADER\", Geeksforgeeks.org, 2019 https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, using VADER, I now have a set of average sentiment scores for each date between the 19th of February, 2003 and the 30th of December, 2019. I will now add this data to the SPYPredictor to see if it is able to predict the movement of SPY better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
